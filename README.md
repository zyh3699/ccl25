<div align="center">
<!-- <img src = "https://github.com/GoThereGit/Chinese-AMR/blob/main/img/camrp2024.png" width=200> -->
</div>

# <p align="center"><font size=50><strong>第一届中文叙实性推理评测任务</strong></font></p> 
<p align="center"><font size=50><strong>Factivity Inference Evaluation 2025</strong></font></p> 

# 报名方式 

请仔细阅读[《第一届中文叙实性推理评测FIE2025参赛协议》](https://github.com/UM-FAH-Yuan/FIE2025/blob/main/Agreement%20%26%20License/%E7%AC%AC%E4%B8%80%E5%B1%8A%E4%B8%AD%E6%96%87%E5%8F%99%E5%AE%9E%E6%80%A7%E6%8E%A8%E7%90%86%E8%AF%84%E6%B5%8B%EF%BC%88FIE2025%EF%BC%89%E5%8F%82%E8%B5%9B%E5%8D%8F%E8%AE%AEv2-20251014.pdf)和[《第一届中文叙实性推理评测FIE2025数据集使用许可》](https://github.com/UM-FAH-Yuan/FIE2025/blob/main/Agreement%20%26%20License/%E7%AC%AC%E4%B8%80%E5%B1%8A%E4%B8%AD%E6%96%87%E5%8F%99%E5%AE%9E%E6%80%A7%E6%8E%A8%E7%90%86%E8%AF%84%E6%B5%8BFIE2025%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BD%BF%E7%94%A8%E8%AE%B8%E5%8F%AFv2-20250114.pdf)，然后点击报名链接进行报名。 （如出现PDF无法显示的情况，请更换浏览器，建议使用Chrome浏览器）

报名链接：https://wj.qq.com/s2/17647837/68cf/

报名注意事项：

- 队长不能作为队员参与其他队伍；
- 队伍成员人数不限。

# 评测赛程 
- 2025年1月：评测任务发布、参赛队伍报名；
- 2025年2月下旬：组织方召开任务说明会
- 2025年3月1日：CCL官方正式发布所有评测任务；
- 2025年3月-5月：各参赛队伍进行模型微调及提示词设计（组织方可为各参赛队伍提供技术指导，指导方式与时间待定）；
- 2025年~~4月中下旬~~ 5月10日（暂定）：组织方发送测试集；
- 2025年~~4月30日~~ 5月15日（暂定）：参赛队伍提交中文叙实性推理评测任务技术报告（中文或英文），用于审稿；
- 2025年5月：组织方对技术报告开展集中评审，提出修改意见；各参赛队伍修改技术报告。
- 2025年6月1日：组织方公布中文叙实性推理评测结果；
- 2025年6月10日：向评测研讨会提交技术报告最终版；
- 2025年6月20日：评测论文审稿 & 录用通知；
- 2025年6月25日：评测论文Camera-ready版提交；
- 2025年7月1日：评测论文纠错排版 & 提交ACL/CCL Anthology收录；
- 2025年8月：CCL 2025技术评测研讨会。

备注：
- 以上时间为北京时间。
- 本任务在4月30日前均接受新的队伍报名参赛，但后期报名的队伍必须以相同标准、按时提交技术报告。

# 1 任务简介

叙实性推理（Factivity Inference, FI）是一种与事件真实性判断有关的语义理解任务，主要涉及语言使用中事实性信息的表达。在人类的会话交际中，叙实性推理能力表现为语言使用者可以从某些动词性语言成分（如“相信”“谎称”“意识到”等）的使用推知其他语言成分所描述的相关事件的真实性（真还是假）。 例如，从肯定句“他们<strong>意识到</strong><ins>局面已经不可挽回</ins>”和相应的否定句“他们<strong>没有意识到</strong><ins>局面已经不可挽回</ins>”上，都可以推理出存在这样一个事实：“局面已经不可挽回”。进行叙实性推理所使用的知识是一种受世界知识（world knowledge）影响较小、主要涉及语言内部各成分之间语义关系的分析性语言知识（analytical knowledge of language）。比如，上面例句中的动词“意识到”要求（预设）它的宾语“局面已经不可挽回”的所指为真，不管该动词前面有没有否定性词语。

叙实性推理和反事实推理（Counter-Factual Inference, CFI）是语义理解中与事件真实性判断有关的两种推理形式，可统称为“真实性推理”（Factuality Inference, FactI）。 相较而言，叙实性推理主要依靠谓词（predicates, 如动词）来表达。例如，从“约翰不知道罗昆是中国人”中“知道”这个动词的使用，可以推理出这样一个事实：“罗昆是中国人”。而反事实推理则主要依靠反事实条件句（counter-factual conditionals）来表达。例如，从“要不是消防队来得及时，大火就要烧到顶楼了”这个反事实条件句中，可以推理出两个事实：“消防队确实来得很及时”和“大火确实没有烧到顶楼”。

作为语言推理的一种重要的导航机制和手段，真实性推理具有明确的语言形式方面的线索，是机器进行文本蕴涵识别（textual entailment recognizing）、幻觉处理（hallucination solving）、信念修正（belief revision）等任务的重要的语义基础和形式依据，同时对信息检索、信息抽取、问题回答、情感分析等下游任务都具有重要的价值。目前，大型语言模型（Large Language Models, LLMs）日益具备类人的与外界自主交互的能力，也被称为“智能体”（agent）。从话语中获取事实性信息及说话人对事件真实性判断的主观态度，这对于智能体的自主推理和人机交互的顺畅性而言是极为关键的。

为了提升大型语言模型对中文的语义理解能力，进一步实现机器对人类实时交际话语的深度理解，我们推出了第一届中文叙实性推理评测（Factivity Inference Evaluation 2025, 简称FIE2025）。

本次评测任务主要关注两方面的问题：
- LLMs的中文叙实性推理表现如何？不同LLMs在不同语境条件下的表现有何差异？
- 不同的提示词（prompts）编写方式（包括但不限于更改shots数量、使用CoT、更改提问句式等）对LLMs的叙实性推理的结果会产生何种影响？什么样的提示词设计可以最大程度上优化LLMs的中文叙实性推理表现？
参赛队伍需要根据评测组织方所提供的测试集自行设计提示词，自主选择合适的模型参加测试，通过API方式向模型提问并获取回答。此次评测在语言大模型的选择、提示词的设计方式与具体的提问方式上均不设限制，鼓励尝试进行多样化、复合化的测试手段，以获得更好的回答表现。

# 2 评测数据 

## 2.1 数据规模与来源

本次评测以JSON格式提供样例集和评测集。由于评测对象为大型语言模型，故而不提供训练集和验证集。

评测集共包含约2000条数据，分为人造语料集与真实语料集两个子集。其中，人造语料集约500条，真实语料集约1500条。

样例集共包含1000条数据，分为人造语料集与真实语料集两个子集。其中，人造语料集300条，真实语料集700条。本次评测不额外提供训练集与验证集，参赛队伍可将样例集数据可用于模型微调训练，并自行从中划分出验证集。

人造语料由评测组织方团队人工构建与标注，并经过3位在叙实性方向颇有建树的语言学家核查校对；真实语料全部筛选自北京大学CCL语料库，并由评测组织方团队进行手工标注与校对。

## 2.2 数据字段

（1）	d_id：数据编号。编号采用“语料类型-数据号”的策略，其中“Art”表示“Artifactual”，“Nat”表示“Natural”，“ArtS”表示“Artifactual Sample”，“NatS”表示“Natural Sample”。

（2）	type：谓词的叙实性类型。此字段只出现在人造语料中。

（3）	predicate：谓词。谓词中大部分为动词，少部分为形容词。人造语料集涉及77个谓词，真实语料集涉及71个谓词。

（4）	text：背景句（主蕴含句）。此字段提供推理所需的语境，模型需要以此为依据来判断结论句的真值情况。

（5）	hypothesis：结论句（被蕴含句）。此字段提供推理所需的鉴别式，模型需要以背景句的内容来判断此句的真值情况。

（6）	option：题目选项。此字段反映模型可能的回答情况，包含4个键，“T”表示根据背景句推理出的结论句的真值为“真”，“F”表示根据背景句推理出的结论句的真值为“假”，“U”表示根据背景句推理出的结论句的真值为“不能确定”，“R”表示模型拒绝回答。

（7）	answer：模型回答。此字段反映模型实际的回答情况，包含4个值“T/F/U/R”，对应"option"字段的4个键。

## 2.3 数据样例

### 2.3.1 人造语料测试集数据样例：

```json
{
        "d_id": "ArtT_0272",
        "type": "反叙实",
        "predicate": "谎称",
        "text": "小张谎称会帮助小李。",
        "hypothesis": "小张会帮助小李。",
        "option": {
            "T": "真",
            "F": "假",
            "U": "不能确定",
            "R": "模型拒绝回答"
        }
    }
```

### 2.3.2 真实语料测试集数据样例：

```json
{
        "d_id": "NatT_5507",
        "predicate": "记得",
        "text": "侯博还记得她叫白冰，是那个大街上对他吐露过内心恋情的女生。",
        "hypothesis": "她确实叫白冰。",
        "option": {
            "T": "真",
            "F": "假",
            "U": "不能确定",
            "R": "模型拒绝回答"
        }
    }
```

### 2.3.3 人造语料样例集数据样例：

```json
{
        "d_id": "ArtS_001",
        "type": "非叙实",
        "predicate": "估计",
        "text": "小张估计小李没生病。",
        "hypothesis": "小李生病了。",
        "option": {
            "T": "真",
            "F": "假",
            "U": "不能确定",
            "R": "模型拒绝回答"
        },
        "answer": "U"
    }
```

### 2.3.4 真实语料样例集数据样例：

```json
{
        "d_id": "NatS_001",
        "predicate": "抱怨",
        "text": "世纪交替之际，联合国各会员国接受会费分摊比额新方案，体现了各国决心加强联合国作用的政治意愿。美国曾长期抱怨自己分摊的比例过大，要求削减会费。现在，美国的这一要求已在很大程度上得到满足。",
        "hypothesis": "美国分摊的比例确实过大。",
        "option": {
            "T": "真",
            "F": "假",
            "U": "不能确定",
            "R": "模型拒绝回答"
        },
        "answer": "T"
    }
```

## 2.4	任务描述

- 参赛队伍需要自行选定若干大型语言模型（型号与规模不限）；利用测试集数据编制提示词，并以API访问的方式逐条发送给被试模型；要求模型以"text"字段值为依据来判断"hypothesis"字段值的真值情况，记录模型的返回结果；最终将结果整理为JSON格式的数据文件。
- 真值情况包括三种：
  - 若根据"text"判定"hypothesis"为真，意味着根据背景句推出结论句的真值为“真”，此时请输出“T”；
  - 若根据"text"判定"hypothesis"为假，意味着根据背景句推出结论句的真值为“假”，此时请输出“F”；
  - 若根据"text"不能判定"hypothesis"的真假，意味着根据背景句推出结论句的真值为“不能确定”，此时请输出“U”。
- 若模型拒绝回答，请输出“R”。
- 若遇到其他问题，请邮件联系任务负责人。
- 参赛队伍使用的所有资源需要在最终提交的技术报告中给予详细说明。实验中的所有代码与结果请妥善保存，以备查用。

## 2.5	数据使用说明与提示

- 参赛队伍需要参考数据内容自行设计与大模型对话时的提示词，因此在数据中未设置"question"字段。
- 提示词格式不限，但在提示词中必须同时包含当前数据中"text"和"hypothesis"字段的内容。
- "type"和"predicate"字段在提示词中既可以出现，也可以不出现。请自行决定是否使用、如何使用"type"和"predicate"字段。
- 提示词的设计可以进行多样化尝试，如提供更多数量的shots、要求使用CoT、要求进行一致性投票、告知动词类型、告知动词的叙实性类型、变换提问句式等等。

## 2.6	输出要求

- 输出文件须为JSON格式，其中每条数据只需包含"d_id"和"answer"两个字段即可。
- 由于所有题目都是单选题，一条数据的"answer"处只允许填写一个值。
- 禁止对模型回答进行人工修正。

## 2.7	输出样例

```json
{
        "d_id": "Nat_0001",
        "answer": "T"
    }
```

## 2.8	评测过程举例

下面我们以编号为"NatS_001"的真实语料样例集中的数据为例展示提示词设计赛道（不微调模型）的评测过程。

- 对于这条数据，我们可以将其改编为一段提示词（prompt）：（注意，此处提示词仅用于介绍举例，不作为模板使用。组织方在正式评测中仅提供数据集，参赛队伍需要充分利用数据信息，尽可能地优化提示词的设计）

```
仅根据text字段的内容，回答hypothesis字段的内容是否为真；只能用“真”“假”或“不能确定”来回答，不能回复其他内容。
"text": "世纪交替之际，联合国各会员国接受会费分摊比额新方案，体现了各国决心加强联合国作用的政治意愿。美国曾长期抱怨自己分摊的比例过大，要求削减会费。现在，美国的这一要求已在很大程度上得到满足。",
"hypothesis": "美国分摊的比例确实过大。"
```

- 选择某大模型（如GPT-o1），通过API访问的方式向其发送这段提示词，等待模型回复。
- 收到模型回答后，将其整理为JSON格式的数据（如下）：

```json
{
        "d_id": "NatS_001",
        "answer": "T"
    }
```
## 2.9	大模型微调设定

经讨论，本次评测将区分“微调模型”与“不微调模型（提示词设计）”两个测试方向。微调方向允许利用样例集数据对模型进行微调（新版样例集已上传，包含1000条数据）；不微调方向则不允许对模型进行任何修改，参赛队伍只能通过优化提示词设计来获取回答。两个测试方向将分开评奖，参赛队伍既可以同时选择参加两个方向的测试，也可以只选择参加其中一个方向的测试。无论选择哪个测试方向，整个测试过程均需在评测报告中作详细说明。


## 2.10 测试基线 （Baseline）

| 微调模型：Qwen2-7B-Instruct | 微调前 | 微调后 |
| ----------------- | ------- | ------- |
| 人造语料集正确率 | 53.74% | 94.66% |
| 自然语料集正确率 | 69.86% | 88.93% |

## 2.11 微调方式参考

基线测试中使用的微调方式已公开，请参考：https://github.com/UM-FAH-Yuan/Factivity-LLM 。

此外，为了方便有需求的队伍进行微调，我们录制了一个访谈式的视频，以简要介绍一种利用Llama Factory来进行lora微调的方法。如需参考，请见https://meeting.tencent.com/crm/KPGoe6dYa8 （密码：0328）。


备注：由于样例集数据量限制，在训练模型时需要自行从样例集中拆分出一部分数据用作验证，因而可能无法完全复现基线结果。


# 3 评价标准 

本次评测采用总正确率作为评价指标:

<div align=center>
<img src="metric.jpg" width="400px">
</div>

其中，**total\_acc** 为总正确率，**correct\_art** 为人造语料集中模型回答正确的数据量，**correct\_nat** 为真实语料集中模型回答正确的数据量，**total\_art** 为人造语料集中的数据总量，**total\_nat** 为真实语料集中的数据总量。

备注：“微调模型”方向将与“不微调模型”方向分开评比。

# 4 技术报告要求 

参与评测必须提交技术报告，不提交技术报告的队伍成绩将不会获得认可。报告要求如下：

1.	报告可由中文或英文撰写。
2.	报告统一使用CCL 2025的论文模板。
3.	报告正文不得超过4页，参考文献页数不限。
4.	报告应至少包含以下四个部分：模型介绍、评测结果、结果分析与讨论和参考文献。
   
如打算向会议投稿，请参考下面的论文格式：

会议投稿需统一使用LaTeX模板。提交的论文最多包含 6 页正文，参考文献页数不限。由于本次会议采用双盲审稿，作者姓名和单位不能出现在投稿的论文中。因此，作者的自引不可采用“我们提出”的方式，而是用“作者名字提出…”。不符合这些要求的论文将不经过完整的审稿流程而直接被拒稿。论文模板下载链接：[http://cips-cl.org/static/CCL2024/downloads/ccl2023_template.zip](http://cips-cl.org/static/CCL2023/downloads/ccl2023_template.zip)（模板可能更新，请保持关注）。

# 5 组织方团队

- 任务组织者：袁毓林（澳门大学教授，yulinyuan@um.edu.mo）、李斌（南京师范大学教授）

- 任务负责人 & 联系人：丛冠良（澳门大学博士生，guanliang.cong@connect.um.edu.mo）

- 团队成员：吴俊潮（澳门大学博士生）、汪月童（澳门大学本科生）、陈可盈（澳门大学硕士生）、寻天琦（澳门大学博士生）、陈阳（澳门大学博士生）、杨梓泓（澳门大学硕士生）
  

# 6 任务奖项 

本届评测将为“微调”与“不微调”两个测试方向分别设置一、二、三等奖，奖项按总正确率从高到低颁发（奖金待定）。其中，每个方向一等奖0-1名，二等奖0-2名，三等奖0-3名。荣誉证书将由中国中文信息学会颁发。

# 7 任务网址 

https://github.com/UM-FAH-Yuan/FIE2025

# 8 参考文献（持续更新）

[1]陈振宇 & 姜毅宁.(2018).事实性与叙实性——通向直陈世界的晦暗与透明. 语言研究集刊(01),15-37+372-373. doi:CNKI:SUN:YJJK.0.2018-01-002.

[2]袁毓林.(2014).隐性否定动词的叙实性和极项允准功能. 语言科学(06),575-586. doi:CNKI:SUN:YYKE.0.2014-06-002.

[3]袁毓林.(2020).“忘记”类动词的叙实性漂移及其概念结构基础. 中国语文(05),515-526+638. doi:CNKI:SUN:YWZG.0.2020-05-001.

[4]袁毓林.(2020).叙实性和事实性：语言推理的两种导航机制. 语文研究(01),1-9. doi:CNKI:SUN:YWYJ.0.2020-01-001.

[5]袁毓林.(2020).“记得”的叙实性漂移及其概念结构基础. 语言教学与研究(01),36-47. doi:CNKI:SUN:YYJX.0.2020-01-007.

[6]袁毓林.(2021).从语言的“多声性”看“假装”句的解读歧异. 语言战略研究(05),77-90. doi:10.19689/j.cnki.cn10-1361/h.20210506.

[7]张帆.(2024).“假装”类动词宾语的类型及其真值判定理据. 中国语言学报(00),157-170. doi:CNKI:SUN:XBYT.0.2024-00-012.

[8]李新良.(2018).“感觉”类动词的叙实性及其漂移问题研究. 语言教学与研究(05),65-75. doi:CNKI:SUN:YYJX.0.2018-05-007.

[9]李新良.(2020). 现代汉语动词的叙实性研究. 北京: 北京大学出版社.

[10]李新良 & 袁毓林.(2016).反叙实动词宾语真假的语法条件及其概念动因. 当代语言学(02),194-215. doi:CNKI:SUN:DDYX.0.2016-02-004.

[11]李新良 & 袁毓林.(2017).“知道”的叙实性及其置信度变异的语法环境. 中国语文(01),42-52+127. doi:CNKI:SUN:YWZG.0.2017-01-003.

[12]李新良、袁毓林等.(2023). 叙实性与事实性理论及其运用. 北京: 外语教学与研究出版社.

[13]Kiparsky & Kiparsky. (1970). Fact. In M. Bierwisch & K. Heidolph (eds.). Progress in Linguistics. The Hague: Mouton. 143-147.


